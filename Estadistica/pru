#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#-----------------------1. Predicción en el caso continuo-----------------------
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#Importamos la base de datos fat del paquete faraway
rm(list = ls(all.names = TRUE))
gc()
library(faraway)
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#-------------------------Preprocesamiento de los datos-------------------------
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_

#Consideramos únicamente las variables de interes
datos = fat[,colnames(fat)[c(1,4:7,9:18)]]
#Veamos las descripciones de cada variable:
#brozek Porcentaje de grasa corporal utilizando la ecuación de Brozek, 457/Densidad - 414,2
#age Edad (años)
#weight Peso (libras)
#height Altura (pulgadas)
#adipos Índice de adiposidad = Peso/Altura$^2$ (kg/$m^2$)
#neck Circunferencia del cuello (cm)
#chest Circunferencia del pecho (cm)
#abdom Circunferencia del abdomen (cm) en el ombligo y al nivel de la cresta ilíaca
#hip Circunferencia de la cadera (cm)
#thigh Circunferencia del muslo (cm)
#knee Circunferencia de la rodilla (cm)
#ankle Circunferencia del tobillo (cm)
#biceps Circunferencia extendida del bíceps (cm)
#forearm Circunferencia del antebrazo (cm)
#wrist Circunferencia de la muñeca (cm) distal a la apófisis estiloides
#Veamos la structura de nuestros datos
str(datos)
#Por la descripción de cada una de nuestras variables, sabemos que no es necesario
#un preprocesamiento de nuestras variables ya que todas pueden ser consideradas como
#variables continuas.
#Ahora veamos un resumen de nuestros datos
summary(datos)
#De este resumen podemos conocer un poco acerca de las personas que formarón este estudio
#* El estudio contiende datos de hombres desde los 22 años hasta los 81 años,
#  la edad promedio es de 45 años.
#* El peso promedio es de 178.9 lbs, sin embargo, se tiene un registro de un peso de
#  363.1 lbs, por lo que mas adelante sera descartado.
#* La altura promedio es de 70.15 pulgadas, sin embargo, se tiene un resgistro de una
#  altura de 29.5 pulgadas, por lo que mas adelante sera descartado.
#* Podemos observar que se tiene un valor de la variable brozek que es cero, por lo que
#  mas adelante sera descartado.
#Eliminamos los registros anteriormente indicados
datos = datos[datos$brozek != 0,]
datos = datos[datos$weight != 363.1,]
datos = datos[datos$height != 29.50,]

#Creamos un DataFrame para ir alamcenando los resultados
models = data.frame(Selección = character(), Datos = character(),Distribución=character(), 
                    Liga = character(), MSE_5CV = numeric())
ligas = c("identity", "inverse", "log")
#1:= Efectos Principales
#2:= Efectos principales e interacciones
#3:= Efectos principales y su version al cuadrado
d = c("1", "2", "3")
dist = c("gaussian", "Gamma")
sel = c("NA", "Stepwise", "Lasso")

#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#i) Considere un modelo lineal generalizado para datos continuos con liga identidad
#y distribución Gaussiana. Explore modelos con los efectos principales de las variables
#así como su interacción (y/o los cuadrados de las variables).
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[1:3,1] = sel[1]
models[1:3,2] = d[1:3]
models[1:3,3] = dist[1]
models[1:3,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Haremos nuestra partición de los datos, donde aproximadamente el 80% de la data será 
#para el train y el 20% restante será para el test. Para ello hacemos lo siguiente:
set.seed (1)
n = dim(datos)[1]
train = sample(1:n, n*.8)
test = (-train)

#Haremos 5-CV por lo que necesitamos un vector con valores del 1 a 5
K=5
labK=rep(1:K, length.out = n)
#Y realizamos una permitación aleatoria de los pliegues
set.seed(123)
Pliegues <- sample(labK)
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, incluyendo solamente efectos principales.
#Ajustemos este modelo
mod1 = lm(brozek  ~., datos)
summary(mod1)
#Hacemos la función para calcular el MSE en cada interacción
mod1_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  mod1t=lm(brozek ~ ., Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}
#Aplicamos 5-CV
MSE.5.mod1 = sapply(1:K,mod1_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[1,5]=mean(MSE.5.mod1))
#17.6787

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, incluyendo efectos principales e
#interacciones.
#Ajustemos este modelo
mod2 = lm(brozek  ~.^2, datos)
summary(mod2)

#Hacemos la función para calcular el MSE en cada interacción
mod2_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  mod2t=lm(brozek ~ .^2, Dat[train,])
  predm2t=predict(mod2t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm2t)^2)
  return(MSE)
}
#Aplicamos 5-CV
MSE.5.mod2= sapply(1:K,mod2_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[2,5]=mean(MSE.5.mod2))
#84.66113

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, incluyendo efectos principales y su
#versión al cuadrado.
#Primero vamos a crear la formula del modelo completo
xnames = colnames(datos)[2:15]
formexp = as.formula(paste('brozek ~.',"+", paste(paste('I(',xnames,'^2)',collapse = ' + ')  ) )) 
#Es evidente que esta formula no depende de las observaciones, por lo que a pesar de
#formar parte del procesamiento de datos, no afecta la división previa que se hizo 
#para los conjuntos train-test.
#Ajustamos el modelo
mod3 = lm(formexp, datos)
summary(mod3)
#Hacemos la función para calcular el MSE en cada interacción
mod3_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  mod3t=lm(formexp, Dat[train,])
  predm3t=predict(mod3t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm3t)^2)
  return(MSE)
}
#Aplicamos 5-CV
MSE.5.mod3= sapply(1:K,mod3_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[3,5]=mean(MSE.5.mod3))
#18.9909

#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#ii) Considere los casos explorados en i), pero realizando selección de variables
# con el criterio AIC.
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[4:6,1] = sel[2]
models[4:6,2] = d[1:3]
models[4:6,3] = dist[1]
models[4:6,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método stepwise (backward) con el criterio AIC, sobre el modelo que solo 
#considera efectos principales.
library("MASS")
#Ajustamos el modelo usando stepwise backward
mod4 = stepAIC(mod1, trace = FALSE)
mod4$formula
summary(mod4)

#Hacemos la función para calcular el MSE en cada interacción
mod4_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(brozek ~ ., Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
#Aplicamos 5-CV
MSE.5.mod4= sapply(1:K,mod4_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[4,5]=mean(MSE.5.mod4))
#17.79291

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método stepwise (backward) con el criterio AIC, sobre el modelo que solo 
#considera efectos principales y sus interacciones.
#Ajustamos el modelo usando stepwise backward
mod5 = stepAIC(mod2, trace = FALSE)
summary(mod5)
#Hacemos la función para calcular el MSE en cada interacción
mod5_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(brozek ~ .^2, Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod5= sapply(1:K,mod5_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
(models[5,5]=mean(MSE.5.mod5))
#45.98253

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método stepwise (backward) con el criterio AIC, sobre el modelo que 
#considera efectos principales y la versión al cuadrado de los mismos
#Ajustamos el modelo usando stepwise backward
mod6 = stepAIC(mod3, trace = FALSE)
sumary(mod6)
#Hacemos la función para calcular el MSE en cada interacción
mod6_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(formexp, Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod6= sapply(1:K,mod6_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[6,5]=mean(MSE.5.mod6))
#18.18705

#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#iii) Considere los casos explorados en i), pero realizando selección de variables
# con el metodo lasso.
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[7:9,1] = sel[3]
models[7:9,2] = d[1:3]
models[7:9,3] = dist[1]
models[7:9,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método lasso, sobre el modelo que solo considera efectos principales.
library(glmnet)
#Agrupamos nuestros datos para usar glmnet
Xmod7 = model.matrix(brozek ~ ., data = datos)[,-1]
Ymod7 = datos[,"brozek"]
#aplicamos lasso
mod7.lasso = glmnet(Xmod7, Ymod7, family = gaussian("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
mod7.lasso.tun = cv.glmnet(Xmod7, Ymod7, nfolds = 5, type.measure ="mse", gamma = 0, 
                           relax = FALSE, family = gaussian("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
mod7.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(mod7.lasso.tun, s = "lambda.min")
#Recordemos que estos estimadores no son EMV
#Así la REGLA FINAL es aquella en donde se usa el lambda seleccionado, en este caso
#el lambda mas pequeño.
#Notemos que la agrupación de nuestros datos para usar glmnet y la definicion (tuneo)
#de lambda deben ser tomados en cuenta en el entrenamiento.
#Ahora si hagamos la medición del poder predictivo

#Hacemos la función para calcular el MSE en cada interacción
mod7RHM=function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  Xmod7ttotal = model.matrix(brozek ~ ., data=Dat)[,-1]
  Xmod7t = Xmod7ttotal[train, ]
  Ymod7t = Dat[train,"brozek"] 
  mod7t.lasso.tun=cv.glmnet(Xmod7t, Ymod7t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = gaussian("identity"), nlambda = 50)
  predte=predict(mod7t.lasso.tun, newx = Xmod7ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}

MSE.5.mod7= sapply(1:K,mod7RHM, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[7,5]=mean(MSE.5.mod7))
# 18.03985

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método lasso, sobre el modelo que considera efectos principales con interacciones
#Agrupamos nuestros datos para usar glmnet
Xmod8 = model.matrix(brozek ~ .^2, data = datos)[,-1]
Ymod8 = datos[,"brozek"]
#Aplicamos lasso
mod8.lasso = glmnet(Xmod8, Ymod8, family = gaussian("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
mod8.lasso.tun = cv.glmnet(Xmod8, Ymod8, nfolds = 5, type.measure ="mse", gamma = 0, 
                           relax = FALSE, family = gaussian("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
mod8.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(mod8.lasso.tun, s = "lambda.min")
#Recordemos que estos estimadores no son EMV
#Así la REGLA FINAL es aquella en donde se usa el lambda seleccionado, en este caso
#el lambda mas pequeño.
#Notemos que la agrupación de nuestros datos para usar glmnet y la definicion (tuneo)
#de lambda deben ser tomados en cuenta en el entrenamiento.
#Ahora si hagamos la medición del poder predictivo
#Hacemos la función para calcular el MSE en cada interacción
mod8RHM=function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  Xmod8ttotal = model.matrix(brozek ~ .^2, data=Dat)[,-1]
  Xmod8t = Xmod8ttotal[train, ]
  Ymod8t = Dat[train,"brozek"] 
  mod8t.lasso.tun=cv.glmnet(Xmod8t, Ymod8t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = gaussian("identity"), nlambda = 50)
  predte=predict(mod8t.lasso.tun, newx = Xmod8ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}

MSE.5.mod8 = sapply(1:K,mod8RHM, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando 5-CV es
(models[8,5]=mean(MSE.5.mod8))
# 17.71160 OJO CUIDAOOOO ALGUNOS WARNING, Aunque creo no es mucho problema

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con liga identidad y distribución Gaussiana, realizando una selección de variables
#usando método lasso, sobre el modelo que considera efectos principales y
#su versión al cuadrado.
#Agrupamos nuestros datos para usar glmnet
Xmod9 = model.matrix(formexp, data = datos)[,-1]
Ymod9 = datos[,"brozek"]
#Aplicamos lasso
mod9.lasso = glmnet(Xmod9, Ymod9, family = gaussian("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
mod9.lasso.tun = cv.glmnet(Xmod9, Ymod9, nfolds = 5, type.measure ="mse", gamma = 0, 
                           relax = FALSE, family = gaussian("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
mod9.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(mod9.lasso.tun, s = "lambda.min")
#Recordemos que estos estimadores no son EMV
#Así la REGLA FINAL es aquella en donde se usa el lambda seleccionado, en este caso
#el lambda mas pequeño.
#Notemos que la agrupación de nuestros datos para usar glmnet y la definicion (tuneo)
#de lambda deben ser tomados en cuenta en el entrenamiento.
#Ahora si hagamos la medición del poder predictivo.
mod9RHM=function(x, Plie, Dat, forme){
  train <- which(Plie != x)
  test = (-train)
  Xmod9ttotal = model.matrix(forme, data=Dat)[,-1]
  Xmod9t = Xmod9ttotal[train, ]
  Ymod9t = Dat[train,"brozek"] 
  mod9t.lasso.tun=cv.glmnet(Xmod9t, Ymod9t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = gaussian("identity"), nlambda = 50)
  predte=predict(mod9t.lasso.tun, newx = Xmod9ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}

MSE.5.mod9 = sapply(1:K,mod9RHM, Plie=Pliegues, Dat=datos, forme = formexp)

#Así el poder predictivo de este modelo usando 5-CV es
(models[9,5]=mean(MSE.5.mod9))
# 17.82026

#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#iv) Explore algun otro modelo lineal generalizado
#_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_
#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelos 
#con distribución Gaussiana y ligas inverse y log, y modelos con distribución Gamma
#con ligas identity, inverse, y log, sobre el modelo que solo considera efectos 
#principales.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[10:14,1] = sel[1]
models[10:14,2] = d[1]
models[10:11,3] = dist[1]
models[10:11,4] = ligas[2:3]
models[12:14,3] = dist[2]
models[12:14,4] = ligas[1:3]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#NOTA: Unicamente se guardará el poder predictivo, y en caso de encontrar una regla 
#con un buen poder predictivo se especificara el modelo de manera explicita
mod_5CV_gau = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(brozek ~ ., family = gaussian(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}
mod_5CV_Gamma = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(brozek ~ ., family = Gamma(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}
nl = length(ligas)
for(i in 2:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_gau, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+8,5]=mean(MSE.5.mod)
}
for(i in 1:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_Gamma, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+11,5]=mean(MSE.5.mod)
}

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelos 
#con distribución Gaussiana y ligas inverse y log, y modelos con distribución Gamma
#con ligas identity, inverse, y log, sobre el modelo que solo considera efectos 
#principales con sus interacciones.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[15:19,1] = sel[1]
models[15:19,2] = d[2]
models[15:16,3] = dist[1]
models[15:16,4] = ligas[2:3]
models[17:19,3] = dist[2]
models[17:19,4] = ligas[1:3]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
mod_5CV_gauV2 = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(brozek ~ .^2, family = gaussian(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}
mod_5CV_GammaV2 = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(brozek ~ .^2, family = Gamma(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}

for(i in 2:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_gauV2, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+13,5]=mean(MSE.5.mod)
}
for(i in 1:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_GammaV2, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+16,5]=mean(MSE.5.mod)
}

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelos 
#con distribución Gaussiana y ligas inverse y log, y modelos con distribución Gamma
#con ligas identity, inverse, y log, sobre el modelo que considera efectos 
#principales y la version al cuadrado de los mismos.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[20:24,1] = sel[1]
models[20:24,2] = d[3]
models[20:21,3] = dist[1]
models[20:21,4] = ligas[2:3]
models[22:24,3] = dist[2]
models[22:24,4] = ligas[1:3]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

mod_5CV_gauV3 = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(formexp, family = gaussian(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}
mod_5CV_GammaV3 = function(x, Plie, Dat, liga){
  train <- which(Plie != x)
  test = (-train)
  mod1t=glm(formexp, family = Gamma(liga) ,Dat[train,])
  predm1t=predict(mod1t, Dat[test,])
  MSE=mean((Dat$brozek[test]-predm1t)^2)
  return(MSE)
}

for(i in 2:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_gauV3, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+18,5]=mean(MSE.5.mod)
}
for(i in 1:nl){
  MSE.5.mod = sapply(1:K,mod_5CV_GammaV3, Plie=Pliegues, Dat=datos, liga = ligas[i])
  models[i+21,5]=mean(MSE.5.mod)
}

#Como podemos observar al usar una distribucion gaussiana con ligas inverse y log
#se obtiene una regla con un mal poder predictivo, en comparación a los modelos en
#donde se uso una distribucion gaussiana con liga identity. Lo mismo sucede al utilizar
#una distribución Gamma con ligas inverse y log. Por lo que para las siguientes
#exploraciones solo se va a considerar la distribución Gamma con liga identity.

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con distribución Gamma y liga identity, sobre los modelos que consideran efectos 
#principales, efectos principales e interacciones entre las mismas, efectos
#principales y su versión al cuadrada. Realizando a la vez seleccion de variables 
#mediante el metodo stepwise con el criterio AIC.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[25:27,1] = sel[2]
models[25:27,2] = d[1:3]
models[25:27,3] = dist[2]
models[25:27,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Efectos principales
mod_5CV_GammaV4 = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=glm(brozek ~ ., family = Gamma("identity") , Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}

MSE.5.mod.GV4 = sapply(1:K,mod_5CV_GammaV4, Plie=Pliegues, Dat=datos)
models[25,5]=mean(MSE.5.mod.GV4)

#Efectos principales e interacciones
mod_5CV_GammaV5 = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=glm(brozek ~ .^2, family = Gamma("identity") , Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
#Tarda un poquito/Mucho
MSE.5.mod.GV5 = sapply(1:K,mod_5CV_GammaV5, Plie=Pliegues, Dat=datos)
models[26,5]=mean(MSE.5.mod.GV5)

#Efectos principales y variables al cuadrado
mod_5CV_GammaV6 = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=glm(formexp, family = Gamma("identity") , Dat[train,])
  modtr=stepAIC(modAux, trace = FALSE)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
#Tarda un poquito/Mucho
MSE.5.mod.GV6 = sapply(1:K,mod_5CV_GammaV6, Plie=Pliegues, Dat=datos)
models[27,5]=mean(MSE.5.mod.GV6)

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar un modelo 
#con distribución Gamma y liga identity, sobre los modelos que consideran efectos 
#principales, efectos principales e interacciones entre las mismas, efectos
#principales y su versión al cuadrada. Realizando a la vez seleccion de variables 
#mediante el lasso.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[28:30,1] = sel[3]
models[28:30,2] = d[1:3]
models[28:30,3] = dist[2]
models[28:30,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Para efectos principales
modRHMV7=function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  Xmod7ttotal = model.matrix(brozek ~ ., data=Dat)[,-1]
  Xmod7t = Xmod7ttotal[train, ]
  Ymod7t = Dat[train,"brozek"] 
  mod7t.lasso.tun=cv.glmnet(Xmod7t, Ymod7t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = Gamma("identity"), nlambda = 50)
  predte=predict(mod7t.lasso.tun, newx = Xmod7ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.modV7= sapply(1:K,modRHMV7, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[28,5]=mean(MSE.5.modV7)

#Para efectos principales con interacciones
modRHMV8=function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  Xmod7ttotal = model.matrix(brozek ~ .^2, data=Dat)[,-1]
  Xmod7t = Xmod7ttotal[train, ]
  Ymod7t = Dat[train,"brozek"] 
  mod7t.lasso.tun=cv.glmnet(Xmod7t, Ymod7t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = Gamma("identity"), nlambda = 50)
  predte=predict(mod7t.lasso.tun, newx = Xmod7ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.modV8= sapply(1:K,modRHMV8, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[29,5]=mean(MSE.5.modV8) #Mucho warning

#Para efectos principales con variables al cuadrado
modRHMV9=function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  Xmod7ttotal = model.matrix(formexp, data=Dat)[,-1]
  Xmod7t = Xmod7ttotal[train, ]
  Ymod7t = Dat[train,"brozek"] 
  mod7t.lasso.tun=cv.glmnet(Xmod7t, Ymod7t, nfolds = 5, type.measure ="mse", gamma = 0, relax = FALSE, family = Gamma("identity"), nlambda = 50)
  predte=predict(mod7t.lasso.tun, newx = Xmod7ttotal[test,], type = "response", s = "lambda.min")
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.modV9 = sapply(1:K,modRHMV9, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[30,5]=mean(MSE.5.modV9)

#DESCRIPCION DEL METODO DE ENTRENAMIENTO Y REGLA FINAL. Vamos a considerar modelos 
#con distribución Gamma con liga identity y con distribución gaussiana con liga identidad, 
#sobre los modelos que consideran efectos  principales, efectos principales e interacciones 
#entre las mismas, efectos principales y su versión al cuadrada. Realizando a la vez 
#seleccion de variables mediante el metodo stepwise con el criterio BIC.
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Guardamos los esquemas
models[31:36,1] = "Stepwise BIC"
models[31:33,2] = d[1:3]
models[31:33,3] = dist[1]
models[34:36,2] = d[1:3]
models[34:36,3] = dist[2]
models[31:33,4] = ligas[1]
models[34:36,4] = ligas[1]
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

#Modelos solo con efectos principales, con distribución gaussiana y liga identity
mod1BIC_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(brozek ~ ., Dat[train,])
  penAux=log(dim(DatosAux)[1])
  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod1BIC= sapply(1:K,mod1BIC_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[31,5]=mean(MSE.5.mod1BIC)

#Modelos con efectos principales e interacciones, con distribución gaussiana y 
#liga identity
mod2BIC_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(brozek ~ .^2, Dat[train,])
  penAux=log(dim(DatosAux)[1])
  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod2BIC= sapply(1:K,mod2BIC_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[32,5]=mean(MSE.5.mod2BIC)
#19.4758

#Modelos solo con efectos principales y variables al cuadrado, con distribución 
#gaussiana y liga identity
mod3BIC_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=lm(formexp, Dat[train,])
  penAux=log(dim(DatosAux)[1])
  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod3BIC= sapply(1:K,mod3BIC_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[33,5]=mean(MSE.5.mod3BIC)

#PARA CORREGIR ERROR SE PUEDE AGREGAR UNA CONSTANTE A LOS DATOS, PERO COMO EL 
#OBJETIVO ES PREDICCION QUIZA NO SEA LO MAS OPTIMO
#Modelos solo con efectos principales, con distribución Gamma y liga identity
#mod4BIC_5CV = function(x, Plie, Dat){
#  train <- which(Plie != x)
#  test = (-train)
#  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
#  modAux=glm(brozek ~ ., family = Gamma("identity"),Dat[train,])
#  penAux=log(dim(DatosAux)[1])
#  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
#  predte=predict(modtr, Dat[test,])
#  MSE=mean((Dat$brozek[test]-predte)^2)
#  return(MSE)
#}
#MSE.5.mod4BIC= sapply(1:K,mod4BIC_5CV, Plie=Pliegues, Dat=datos+2)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
#(models[34,5]=mean(MSE.5.mod4BIC))

#TARDA UN POQUITO/MUCHO
#Modelos con efectos principales e interacciones, con distribución Gamma y 
#liga identity
mod5BIC_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=glm(brozek ~ .^2,  family = Gamma("identity"), Dat[train,])
  penAux=log(dim(DatosAux)[1])
  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod5BIC= sapply(1:K,mod5BIC_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[35,5]=mean(MSE.5.mod5BIC)
#19.4758

#Modelos solo con efectos principales y variables al cuadrado, con distribución 
#Gamma y liga identity
mod6BIC_5CV = function(x, Plie, Dat){
  train <- which(Plie != x)
  test = (-train)
  assign("DatosAux", Dat[train,], envir = .GlobalEnv)
  modAux=glm(formexp, family = Gamma("identity"), Dat[train,])
  penAux=log(dim(DatosAux)[1])
  modtr=stepAIC(modAux, trace = FALSE, k = penAux)
  predte=predict(modtr, Dat[test,])
  MSE=mean((Dat$brozek[test]-predte)^2)
  return(MSE)
}
MSE.5.mod6BIC= sapply(1:K,mod6BIC_5CV, Plie=Pliegues, Dat=datos)

#Así el poder predictivo de este modelo usando MSE y 5-CV es
models[36,5]=mean(MSE.5.mod6BIC)
#19.4758
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#Hagamos los modelos para la distribución Gamma y liga identidad
#1
modG1 = glm(brozek ~ ., family = Gamma("identity"), data = datos)
summary(modG1)
#2
modG2 = glm(brozek ~ .^2, family = Gamma("identity"), data = datos)
summary(modG2)
#3
modG3 = glm(formexp, family = Gamma("identity"), data = datos)
summary(modG3)
#1 con stepwise
modG4 = stepAIC(modG1, trace = FALSE)
summary(modG4)
#2 con stepwise
modG5 = stepAIC(modG2, trace = FALSE)
summary(modG5)
#3 con stepwise
modG6 = stepAIC(modG3, trace = FALSE)
summary(modG6)
#1 con lasso
#Agrupamos nuestros datos para usar glmnet
XmodG7 = model.matrix(brozek ~ ., data = datos)[,-1]
YmodG7 = datos[,"brozek"]
#Aplicamos lasso
modG7.lasso = glmnet(XmodG7, YmodG7, family = Gamma("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
modG7.lasso.tun = cv.glmnet(XmodG7, YmodG7, nfolds = 5, type.measure ="mse", gamma = 0, 
                           relax = FALSE, family = Gamma("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
modG7.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(modG7.lasso.tun, s = "lambda.min")

#2 con lasso
#Agrupamos nuestros datos para usar glmnet
XmodG8 = model.matrix(brozek ~ .^2, data = datos)[,-1]
YmodG8 = datos[,"brozek"]
#Aplicamos lasso
modG8.lasso = glmnet(XmodG8, YmodG8, family = Gamma("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
modG8.lasso.tun = cv.glmnet(XmodG8, YmodG8, nfolds = 5, type.measure ="mse", gamma = 0, 
                            relax = FALSE, family = Gamma("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
modG8.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(modG8.lasso.tun, s = "lambda.min")

#3 con lasso
#Agrupamos nuestros datos para usar glmnet
XmodG9 = model.matrix(formexp, data = datos)[,-1]
YmodG9 = datos[,"brozek"]
#Aplicamos lasso
modG9.lasso = glmnet(XmodG9, YmodG9, family = Gamma("identity"), nlambda = 200)
#Ahora vamos a (tunear) definir el valor de lambda
set.seed(1)
modG9.lasso.tun = cv.glmnet(XmodG9, YmodG9, nfolds = 5, type.measure ="mse", gamma = 0, 
                            relax = FALSE, family = Gamma("identity"), nlambda = 50)
#Veamos cual es el valor de esta lambda
modG9.lasso.tun$lambda.min
#Vemos cuales son las variables y los coeficientes resultantes al usar esta variable
coef(modG9.lasso.tun, s = "lambda.min")

#stepwise backward con criterio BIC al modelo que solo considera efectos principales
#con distribucion gaussiana y liga identidad
mod1BIC = stepAIC(mod1, trace = FALSE, k=log(dim(datos)[1]))
summary(mod1BIC)

#stepwise backward con criterio BIC al modelo que considera efectos principales
#con interacciones con distribucion gaussiana y liga identidad
mod2BIC = stepAIC(mod2, trace = FALSE, k=log(dim(datos)[1]))
summary(mod2BIC)

#stepwise backward con criterio BIC al modelo que considera efectos principales
#y variables al cuadrado con distribucion gaussiana y liga identidad
mod3BIC = stepAIC(mod3, trace = FALSE, k=log(dim(datos)[1]))
summary(mod3BIC)

#stepwise backward con criterio BIC al modelo que solo considera efectos principales
#con distribucion Gamma y liga identidad
mod4BIC = stepAIC(modG1, trace = FALSE, k=log(dim(datos)[1]))
summary(mod4BIC)

#stepwise backward con criterio BIC al modelo que considera efectos principales
#con interacciones con distribucion gaussiana y liga identidad
mod5BIC = stepAIC(modG2, trace = FALSE, k=log(dim(datos)[1]))
summary(mod5BIC)

#stepwise backward con criterio BIC al modelo que considera efectos principales
#y variables al cuadrado con distribucion gaussiana y liga identidad
mod6BIC = stepAIC(modG3, trace = FALSE, k=log(dim(datos)[1]))
summary(mod6BIC)
#+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

#Guardamos el dataframe models en un excel
#library(openxlsx)
#modE1TE3 <- models
#modE1TE3 <- write.xlsx(modE1TE3,".xlsx")
#saveWorkbook(modE1TE3, file= "modE1TE3.xlsx", overwrite = TRUE)
